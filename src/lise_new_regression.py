# -*- coding: utf-8 -*-
"""lise-new-regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m504pqOh2o9a4_FH29wkZX_4yq0raeJt

# Lise Notlarının Backward Elimination İle Değişken Seçimi Ve Regresyon Modelleri
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import plot_confusion_matrix
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVR
import sklearn

os.chdir("D:\Belgeler\Çalışmalar\Bitirme-MEB")

data_file = "Data/Veriseti_Anadolu_Liseleri_GONDERILEN.xlsx"
data_original = pd.read_excel(data_file, engine="openpyxl")
df = data_original.copy()
df = df.drop(columns=["okuladi", "okulno"])
df.head()

df.dtypes

df.iloc[:, -7:] = df.iloc[:, -7:].astype("int64")

df.dtypes

"""Hayır=1 Evet=0 değerlerini Hayır=0 Evet=1 olarak değiştirelim;"""

def sifir_bir_duzelt(degisken):
  for i in df[degisken].index:
    if df[degisken][i] ==0:
      df[degisken][i] = 1
    elif df[degisken][i]==1:
      df[degisken][i]=0

sifir_bir_duzelt("Asag")
sifir_bir_duzelt("Bsag")
sifir_bir_duzelt("Aoz")
sifir_bir_duzelt("Boz")
sifir_bir_duzelt("ABayri")
sifir_bir_duzelt("Abirlikte")
sifir_bir_duzelt("Acalisma")
sifir_bir_duzelt("Bcalisma")
sifir_bir_duzelt("oda")
sifir_bir_duzelt("hastalik")
sifir_bir_duzelt("okul_dyk")
sifir_bir_duzelt("ozel_kurs")
sifir_bir_duzelt("ortaokul_kurs")
sifir_bir_duzelt("ortaokul_ozelders")

df.head()

"""# Aykırı Değer Tespiti"""

sns.boxplot(x = df.ort9)

sns.boxplot(x = df.lgs_puani)

Q1 = df.lgs_puani.quantile(0.25)
Q3 = df.lgs_puani.quantile(0.75)
IQR = Q3-Q1
lower = Q1 - 1.5*IQR
upper = Q3 + 1.5*IQR
df.loc[df["lgs_puani"] > upper,"lgs_puani"] = upper
df.loc[df["lgs_puani"] < lower,"lgs_puani"] = lower
sns.boxplot(x = df.lgs_puani)

Q1 = df.ort9.quantile(0.25)
Q3 = df.ort9.quantile(0.75)
IQR = Q3-Q1
lower = Q1 - 1.5*IQR
upper = Q3 + 1.5*IQR
df.loc[df["ort9"] > upper,"ort9"] = upper

sns.boxplot(x = df.ort9)

"""## Standardization"""

# Get column names first
names = df.columns
# Create the Scaler object
scaler = preprocessing.StandardScaler()
# Fit your data on the scaler object
scaled_df = scaler.fit_transform(df)
scaled_df = pd.DataFrame(scaled_df, columns=names)

scaled_df

"""# `ort9` değişkeni ile Backward Elimination ve Regresyon Analizi"""

df_data = scaled_df.drop(["ort10", "ort11"], axis=1)

x = scaled_df.drop(["ort9", "ort10", "ort11"], axis=1)
y = scaled_df["ort9"]

def backward_elimination(data, target,significance_level = 0.05):
  features = data.columns.tolist()
  while(len(features)>0):
    features_with_constant = sm.add_constant(data[features])
    p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]
    max_p_value = p_values.max()

    if(max_p_value >= significance_level):
      excluded_feature = p_values.idxmax()
      features.remove(excluded_feature)
    else:
      break 
  return features

ort9_futures = backward_elimination(x, y)

ort9_futures

"""## Regresyon Analizi"""

x = df_data[ort9_futures]
y = df_data["ort9"]

"""İstatistik modellerini kullandığımız için, sabit terimi X değerine eklememiz gerekiyor."""

x = sm.add_constant(x)

train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 42)

model = sm.OLS(y, x)
model = model.fit()
print(model.summary2())

"""Değişkenlerin sonuca etki yüzdelerini inceleyelim;"""

coefs = model.params
coefs = pd.DataFrame(coefs, columns=["coefficients"])
coefs.drop(index=["const"], inplace=True)
coefs

coef_sum = coefs.coefficients.abs().sum()
coefs_abs = coefs.coefficients.abs().values
coefs_abs

percentages = []
for i in coefs_abs:
  perc = i*100/coef_sum
  percentages.append(perc)

coefs["Percentages"] = percentages

coefs.sort_values(by="Percentages", ascending=False, inplace=True)
print(coefs)

"""### Split Data"""

#x = df[["ders_calisma", 
#        "internet", "Asag", "okul_dyk", 
#        "turkce9","mat9", "lgs_puani"]]
x = df[ort9_futures]
#x=x.drop(columns=['Aogrenim'])
y = df["ort9"]

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

train_x

"""### Specify and Fit the Model"""

from sklearn.svm import SVR
model =SVR(C= 1000, gamma= 0.0001, kernel= 'rbf')

accuracies=cross_val_score(model,x,y,cv=5)
print("Accuracy (mean): %", accuracies.mean()*100)
print("std: %", accuracies.std()*100)
scores=cross_val_score(model,x,y,scoring='neg_mean_absolute_error',cv=5)
print("MAE (mean): %",scores.mean())

model.fit(train_x, train_y)

sklearn.__version__

import pickle
model_path = "ort9.pickle"
pickle.dump(model, open(model_path, "wb"))

"""###  Make Predictions with Validation Data"""

load_model_path="ort9.pickle"
loaded_model = pickle.load(open(load_model_path, "rb"))

val_predictions = loaded_model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

#val_predictions = scaler_valy.inverse_transform(val_predictions)
val_predictions = val_predictions.astype("int64")
val_predictions

"""### Modelin manuel test edilmesi"""

val_x

load_model_path="ort9.pickle"
loaded_model = pickle.load(open(load_model_path, "rb"))

girdiler = [1,4,3,0,375.0,62,56]
data_girdi=pd.DataFrame(columns=['Asag','Aogrenim','internet','okul_dyk','lgs_puani','turkce9','mat9'])
data_girdi = data_girdi.append({'Asag': girdiler[0],
                                'Aogrenim': girdiler[1],
                                'internet': girdiler[2],
                                'okul_dyk': girdiler[3],
                                'lgs_puani': girdiler[4],
                                'turkce9': girdiler[5],
                                'mat9': girdiler[6]},
                                ignore_index=True)

data_girdi

data_girdi=data_girdi.iloc[:,:].astype("int64")

girdi=data_girdi
print(girdi)
cikti=loaded_model.predict(girdi)
print(cikti)



cikti = cikti.astype("int64")
cikti

val_y

"""# `ort10` değişkeni ile Backward Elimination ve Regresyon Analizi"""

df_data = scaled_df.drop(["ort11"], axis=1)

x = scaled_df.drop(["ort10", "ort11"], axis=1)
y = scaled_df["ort10"]

def backward_elimination(data, target,significance_level = 0.05):
  features = data.columns.tolist()
  while(len(features)>0):
    features_with_constant = sm.add_constant(data[features])
    p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]
    max_p_value = p_values.max()

    if(max_p_value >= significance_level):
      excluded_feature = p_values.idxmax()
      features.remove(excluded_feature)
    else:
      break 
  return features

ort10_futures = backward_elimination(x, y)

ort10_futures

"""## Regresyon Analizi"""

x = df_data[ort10_futures]
y = df_data["ort10"]

"""İstatistik modellerini kullandığımız için, sabit terimi X değerine eklememiz gerekiyor."""

x = sm.add_constant(x)

train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 42)

model = sm.OLS(y, x)
model = model.fit()
print(model.summary2())

"""Değişkenlerin sonuca etki yüzdelerini inceleyelim;"""

coefs = model.params
coefs = pd.DataFrame(coefs, columns=["coefficients"])
coefs.drop(index=["const"], inplace=True)
coefs

coef_sum = coefs.coefficients.abs().sum()
coefs_abs = coefs.coefficients.abs().values
coefs_abs

percentages = []
for i in coefs_abs:
  perc = i*100/coef_sum
  percentages.append(perc)

coefs["Percentages"] = percentages

coefs.sort_values(by="Percentages", ascending=False, inplace=True)
print(coefs)

"""### Split Data"""

x = df[ort10_futures]
#x=x.drop(columns=["internet", "Boz", "sosyal_kulturel"])
y = df["ort10"]

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

train_x

"""### Specify and Fit the Model"""

from sklearn.svm import SVR
model =SVR(C= 1000, gamma= 0.0001, kernel= 'rbf')

accuracies=cross_val_score(model,x,y,cv=5)
print("Accuracy (mean): %", accuracies.mean()*100)
print("std: %", accuracies.std()*100)
scores=cross_val_score(model,x,y,scoring='neg_mean_absolute_error',cv=5)
print("MAE (mean): %",scores.mean())

model.fit(train_x, train_y)

import pickle
model_path = "ort10.pickle"
pickle.dump(model, open(model_path, "wb"))

"""###  Make Predictions with Validation Data"""

load_model_path="ort10.pickle"
loaded_model = pickle.load(open(load_model_path, "rb"))

val_predictions = loaded_model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

#val_predictions = scaler_valy.inverse_transform(val_predictions)
val_predictions = val_predictions.astype("int64")
val_predictions

"""### Modelin manuel test edilmesi"""

val_x

load_model_path="ort10.pickle"
loaded_model = pickle.load(open(load_model_path, "rb"))

girdiler = [0,1,3,4,0,0,0,375, 67]
data_girdi=pd.DataFrame(columns=['cinsiyet','Boz','internet','ders_calisma','okul_dyk','sosyal_kulturel','ortaokul_turu',"lgs_puani",'ort9'])
data_girdi = data_girdi.append({'cinsiyet': girdiler[0],
                                'Boz': girdiler[1],
                                'internet': girdiler[2],
                                'ders_calisma': girdiler[3],
                                'okul_dyk': girdiler[4],
                                'sosyal_kulturel': girdiler[5],
                                'ortaokul_turu': girdiler[6],
                                'lgs_puani': girdiler[7],
                                'ort9': girdiler[8]},
                                ignore_index=True)

data_girdi

data_girdi=data_girdi.iloc[:,:].astype("int64")

girdi=data_girdi
print(girdi)
cikti=loaded_model.predict(girdi)
print(cikti)



cikti = cikti.astype("int64")
cikti

val_y

"""# `ort11` değişkeni ile Backward Elimination ve Regresyon Analizi"""

df_data = scaled_df

x = scaled_df.drop(["ort11"], axis=1)
y = scaled_df["ort11"]

def backward_elimination(data, target,significance_level = 0.05):
  features = data.columns.tolist()
  while(len(features)>0):
    features_with_constant = sm.add_constant(data[features])
    p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]
    max_p_value = p_values.max()

    if(max_p_value >= significance_level):
      excluded_feature = p_values.idxmax()
      features.remove(excluded_feature)
    else:
      break 
  return features

ort11_futures = backward_elimination(x, y)

ort11_futures

"""## Regresyon Analizi"""

x = df_data[ort11_futures]
y = df_data["ort11"]

"""İstatistik modellerini kullandığımız için, sabit terimi X değerine eklememiz gerekiyor."""

x = sm.add_constant(x)

train_x, test_x, train_y, test_y = train_test_split(x, y, train_size = 0.8, random_state = 42)

model = sm.OLS(y, x)
model = model.fit()
print(model.summary2())

"""Değişkenlerin sonuca etki yüzdelerini inceleyelim;"""

coefs = model.params
coefs = pd.DataFrame(coefs, columns=["coefficients"])
coefs.drop(index=["const"], inplace=True)
coefs

coef_sum = coefs.coefficients.abs().sum()
coefs_abs = coefs.coefficients.abs().values
coefs_abs

percentages = []
for i in coefs_abs:
  perc = i*100/coef_sum
  percentages.append(perc)

coefs["Percentages"] = percentages

coefs.sort_values(by="Percentages", ascending=False, inplace=True)
print(coefs)

"""### Split Data

**`ort11` değişkeninin tahmininde alt değişken tespit çalışması sonucunda elde edilen sonuçlara göre `ders_calisma` sütunu eğitim veri setine dahil edilmiştir. Bu ekleme sonucunda %0.25 iyileşme gerçekleşmiştir.**
"""

x = df[["cinsiyet","ABayri","okul_dyk","ders_calisma","sosyal_kulturel","turkce9","ort10"]]
#x = df[ort11_futures]
#x=x.drop(columns=["okul_dyk"])
y = df["ort11"]

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

train_x

"""### Specify and Fit the Model"""

model =SVR(C= 1000, gamma= 0.0001, kernel= 'rbf')

'''param_grid = {"cv" = [2, 3, 5, 7, 10]
              }

CV_rfc = GridSearchCV(estimator=model, param_grid=param_grid, cv= 5)
CV_rfc.fit(train_x, train_y)
print(CV_rfc.best_params_)'''

accuracies=cross_val_score(model,x,y,cv=5)
print("Accuracy (mean): %", accuracies.mean()*100)
print("std: %", accuracies.std()*100)
scores=cross_val_score(model,x,y,scoring='neg_mean_absolute_error',cv=5)
print("MAE (mean): %",scores.mean())

model.fit(train_x, train_y)

import pickle
model_path = "ort11.pickle"
pickle.dump(model, open(model_path, "wb"))

"""###  Make Predictions with Validation Data"""

load_model_path="ort11.pickle"
loaded_model = pickle.load(open(load_model_path, "rb"))

val_predictions = loaded_model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

#val_predictions = scaler_valy.inverse_transform(val_predictions)
val_predictions = val_predictions.astype("int64")
val_predictions

"""### Modelin manuel test edilmesi"""

val_x

load_model_path="ort11.pickle"
loaded_model = pickle.load(open(load_model_path, "rb"))

girdiler = [0,0,0,3,0,88,91]
data_girdi=pd.DataFrame(columns=["cinsiyet","ABayri","okul_dyk","ders_calisma","sosyal_kulturel","turkce9","ort10"])
data_girdi = data_girdi.append({'cinsiyet': girdiler[0],                              
                                'ABayri': girdiler[1],
                                'okul_dyk': girdiler[2],
                                'ders_calisma': girdiler[3],
                                'sosyal_kulturel': girdiler[4],
                                'turkce9': girdiler[5],
                                'ort10': girdiler[6]},
                                ignore_index=True)

data_girdi

data_girdi=data_girdi.iloc[:,:].astype("int64")

girdi=data_girdi
print(girdi)
cikti=loaded_model.predict(girdi)
print(cikti)



cikti = cikti.astype("int64")
cikti

val_y