# -*- coding: utf-8 -*-
"""Ortaokul_Tahmin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15GjBXG_6CBQwlc-eO9rj7vCWzoLLitX4

# Feature Selection

Modelinizin iyi bir performans göstermesi için boyutsallığının azaltılması ve güçlü ilişkilere sahip
parametrelerin, performansı kötü etkileyecek diğer parametrelerden ayrılması gerekir. Çünkü bu
öznitelikler (features) modele bir bilgi getirmiyor olabilirler.
Pekala boyut düşürmenin veya öznitelik azaltmanın yararları nedir:
- Daha yüksek doğruluk oranı
- Overfitting probleminin önüne geçmek.
- Model eğitim süresinin kısaltılması.
- Daha etkin bir görselleştirme
- Daha açıklanabilir bir model.

Veri madenciliği sürecinin önemli aşamalarından biri veri boyutunun
azaltılması işlemidir. Veri boyutunun azaltılması kısaca, büyük veri kümelerinin
depolanması ve analiz edilmesinde karşılaşılan sorunları aşmak için veri
kümesinden ilgisiz veya gereksiz değişkenlerin çıkartılması olarak
tanımlanmaktadır. Veri boyutunun azaltılması için kullanılan yöntemlerin başında
özellik seçimi gelmektedir. Özellik seçimi, orijinal veri setini temsil edebilecek en
iyi altkümenin seçimi olarak tanımlanmaktadır. Bu işlem, ilgilenilen problem için
en faydalı ve en önemli özellikleri seçerek veri kümesindeki özellik sayısını
azaltmayı yani veri boyutunu düşürmeyi amaçlamaktadır.
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix

os.chdir("/content/drive/MyDrive/Works/Bitirme")

data_file = "Data/Veriseti_Ortaokullar_GONDERILEN.xlsx"
data_original = pd.read_excel(data_file)
df = data_original.copy()
#df = df.drop(columns=["okuladi", "okulno"])
df.head()

"""#Aykırı Değer Düzeltme"""

sns.boxplot(x = df.ort7)

df.dtypes

df.iloc[:, -3:] = df.iloc[:, -3:].astype("int64")

df.dtypes

"""`ort7` = 7. sınıf ortalaması tahmin edilecek."""

def sifir_bir_duzelt(degisken):
  for i in df[degisken].index:
    if df[degisken][i] ==0:
      df[degisken][i] = 1
    elif df[degisken][i]==1:
      df[degisken][i]=0

sifir_bir_duzelt("Asag")
sifir_bir_duzelt("Bsag")
sifir_bir_duzelt("Aoz")
sifir_bir_duzelt("Boz")
sifir_bir_duzelt("ABayri")
sifir_bir_duzelt("Abirlikte")
sifir_bir_duzelt("Acalisma")
sifir_bir_duzelt("Bcalisma")
sifir_bir_duzelt("oda")
sifir_bir_duzelt("hastalik")
sifir_bir_duzelt("okul_dyk")
sifir_bir_duzelt("ozel_kurs")

x = df #degiskenler
y = df.ort7 #tahmin edilecek

x.head()

x.corr()

fig, ax = plt.subplots(figsize=(30,20)) 
sns.heatmap(df.corr(), annot=True, linewidths=0.3, ax=ax)
plt.savefig("heatmap.png")

"""#Cinsiyetlere göre korelasyonları inceleyelim;"""

df_kadin = x["cinsiyet"] == 0
x_kadin = x[df_kadin]

df_erkek = x["cinsiyet"] == 1
x_erkek = x[df_erkek]

"""##Kadın ve erkekler ile korelasyonlar;"""

x.corr().abs()["ort7"].nlargest(10)

"""##Kadınlar için korelasyonlar;"""

fig, ax = plt.subplots(figsize=(30,20)) 
sns.heatmap(x_kadin.corr(), annot=True, linewidths=0.3, ax=ax)
plt.savefig("kadin_heatmap.png")

x_kadin.corr().abs()["ort7"].nlargest(10)

"""##Erkekler için korelasyonlar;


"""

fig, ax = plt.subplots(figsize=(30,20)) 
sns.heatmap(x_erkek.corr(), annot=True, linewidths=0.3, ax=ax)
plt.savefig("erkek_heatmap.png")

x_erkek.corr().abs()["ort7"].nlargest(10)

"""Kolay karşılaştırmak için tekrar getirelim;"""

x_kadin.corr().abs()["ort7"].nlargest(10)

kadin_desc = x_kadin.describe().T

erkek_desc = x_erkek.describe().T

pd.concat([kadin_desc, erkek_desc], axis=1)

"""Bu zamana kadar yazdığımız kısmın sonunda index metodunu ekleyerek sadece kolon isimlerini
istiyorum ve bunu ana datasetimizden başka bir değişkene aktarıyorum. Birazdan sadece bu kısmı
kullanıyor olacağız, bu sayede daha okunaklı ve en yüksek 10 korelasyon değerine sahip kolon ile
birlikte çalışıyor olacağız.
"""

x_reduced_col_names = x.corr().abs()["ort7"].nlargest(10).index
x[x_reduced_col_names].corr()

x = x[x_reduced_col_names]
x.dtypes



fig, ax = plt.subplots(figsize=(10,10), dpi=100) 
sns.set(font_scale=1.2)
sns.heatmap(x[x_reduced_col_names].corr(), annot=True, linewidths=0.3, ax=ax)
plt.xticks(rotation=60)
plt.savefig("reduced_heatmap.png")

"""**Burada ozel_ders değişkeninde Evet = 0, Hayır = 1 olarak atandığı için pozitif çıkması gereken korelasyon negatif gözükmektedir.**

# Split Data
"""

x = x.drop("ort7", axis=1)
y = df.ort7

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

"""# Specify and Fit the Model

#Decision Tree Regressor

`DecisionTreeRegressor` modeli oluşturalım ve ilgili veriler ile eğitelim.
"""

model = DecisionTreeRegressor(max_depth=3)

model.fit(train_x, train_y)

"""#  Make Predictions with Validation Data"""

val_predictions = model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

print(val_predictions[:5], "\n")

print(val_y.head())

val_predictions[-10:]

val_y[-10:]

"""#Calculate the Mean Absolute Error in Validation Data """

val_mae = mean_absolute_error(val_y, val_predictions)

print(val_mae)

pred = val_predictions[-10:].astype("int64")
org = val_y[-10:].values
df_pred = pd.DataFrame({"preds" : pred, "labels":org})
df_pred

"""#XGBoost

Structured veriler için en doğru sonuçları veren modelleme tekniği.
"""

XGB_model = XGBRegressor()

XGB_model.fit(train_x, train_y)

predictions = XGB_model.predict(val_x)
print('Eğitim doğruluğu :',XGB_model.score(train_x,train_y)*100)
print('Test doğruluğu :',XGB_model.score(val_x,val_y)*100)
print("Mean Absolute Error: " + str(mean_absolute_error(predictions, val_y)))

"""## Parameter Tuning

XGBoost, doğruluğu ve eğitim hızını önemli ölçüde etkileyebilecek birkaç parametreye sahiptir.
"""

XGB_model = XGBRegressor(n_estimators=500, 
                         learning_rate=0.25, 
                         max_depth=3,
                         min_child_weight=5, 
                         colsample_bytree=0.4
                         )
XGB_model.fit(train_x, train_y,
              early_stopping_rounds = 5,
              eval_set=[(val_x, val_y)],
              
              verbose=False)

predictions = XGB_model.predict(val_x)

print('Eğitim doğruluğu :',XGB_model.score(train_x,train_y)*100)
print('Test doğruluğu :',XGB_model.score(val_x,val_y)*100)
print("Mean Absolute Error: " + str(mean_absolute_error(predictions, val_y)))

val_predictions = XGB_model.predict(val_x)

print(val_predictions[:5], "\n")

print(val_y.head())

pred = val_predictions[-10:].astype("int64")
org = val_y[-10:].values
df_pred = pd.DataFrame({"preds" : pred, "labels":org})
df_pred

"""

---

# Classification
"""

data_file = "Data/Veriseti_Ortaokullar_GONDERILEN.xlsx"
data_original = pd.read_excel(data_file)
df = data_original.copy()
df = df.drop(columns=["okuladi", "okulno"])
df.head()

df.iloc[:, -3:] = df.iloc[:, -3:].astype("int64")

df

def sifir_bir_duzelt(degisken):
  for i in df[degisken].index:
    if df[degisken][i] ==0:
      df[degisken][i] = 1
    elif df[degisken][i]==1:
      df[degisken][i]=0

sifir_bir_duzelt("Asag")
sifir_bir_duzelt("Bsag")
sifir_bir_duzelt("Aoz")
sifir_bir_duzelt("Boz")
sifir_bir_duzelt("ABayri")
sifir_bir_duzelt("Abirlikte")
sifir_bir_duzelt("Acalisma")
sifir_bir_duzelt("Bcalisma")
sifir_bir_duzelt("oda")
sifir_bir_duzelt("hastalik")
sifir_bir_duzelt("okul_dyk")
sifir_bir_duzelt("ozel_kurs")





def puan_olcegi(ort):
  for i in df[ort].index:
    if df[ort][i] >=0 and df[ort][i] <= 24:
      df[ort][i] = 0
    elif df[ort][i] >=25 and df[ort][i] <= 44:
      df[ort][i] = 1
    elif df[ort][i] >= 45 and df[ort][i] <=54:
      df[ort][i] = 2
    elif df[ort][i] >= 55 and df[ort][i] <=69:
      df[ort][i] = 3
    elif df[ort][i] >= 70 and df[ort][i] <=84:
      df[ort][i] = 4
    elif df[ort][i] >= 85 and df[ort][i] <=100:
      df[ort][i] = 5

puan_olcegi(ort = "ort5")
puan_olcegi(ort = "ort6")
puan_olcegi(ort = "ort7")

df

"""## Feature Selection"""

x_cl = df #degiskenler
y_cl = df.ort7 #tahmin edilecek

x_cl.head()

x_cl.corr()

fig, ax = plt.subplots(figsize=(30,20)) 
sns.heatmap(df.corr(), annot=True, linewidths=0.3, ax=ax)
plt.savefig("heatmap_classification.png")

x_cl.corr().abs()["ort7"].nlargest(10)

x_cl_reduced_col_names = x_cl.corr().abs()["ort7"].nlargest(10).index
x_cl[x_cl_reduced_col_names].corr()

x_cl = x_cl[x_cl_reduced_col_names]
x_cl.dtypes

fig, ax = plt.subplots(figsize=(10,10), dpi=100) 
sns.heatmap(x_cl[x_cl_reduced_col_names].corr(), annot=True, linewidths=0.3, ax=ax)
plt.savefig("reduced_cl_heatmap.png")

"""## Split Data"""

x_cl = x_cl.drop("ort7", axis=1)
y_cl = df.ort7

train_x, val_x, train_y, val_y = train_test_split(x_cl, y_cl, random_state=42)

"""##Specify and Fit the Model

### Multinomial Logistic Regression

Üç veya daha fazla kategoriye sahip verileri sınıflandırmak için kullanılan bir Logistic Regression yöntemidir.
"""

ort_logistic = LogisticRegression()

ort_logistic.fit(train_x, train_y)

base_model_predicts = ort_logistic.predict(val_x)
print('Accuracy from base model train data : {0}'.format(ort_logistic.score(train_x, train_y)))
print('Accuracy from base model test data: {0}'.format(ort_logistic.score(val_x, val_y)))

custom_ort_logistic = LogisticRegression( penalty = "l2", C=100)

custom_ort_logistic.fit(train_x,train_y)

custom_model_predicts = custom_ort_logistic.predict(val_x)
print('Accuracy from base model train data : {0}'.format(custom_ort_logistic.score(train_x, train_y)))
print('Accuracy from base model test data: {0}'.format(custom_ort_logistic.score(val_x, val_y)))

base_model_accuracy = ort_logistic.score(val_x,val_y)*100
custom_model_accuracy = custom_ort_logistic.score(val_x,val_y)*100

plt.bar("Custom model",custom_model_accuracy)
plt.bar("Base model",base_model_accuracy)
plt.yticks([0,20,40,60,70,80,100])
plt.title('Accuracies for Custom and Base models')
plt.show()

"""Modelimizi varsayılan lineer regresyon algoritmasıyla ve varsayılan ve özel parametrelerle eğittik. Test verileri için hangisinin daha iyi sonuç verdiğini gördük. Bu sefer özelleştirilmiş parametre daha iyi sonuç verdi, ama bilirlik oranı eğitim verileri ve test verilerine göre değişiklik gösterebilir.

###K-Nearest Neighbor Algorithm (KNN)

Bu algoritma veri setimize göre yapılan tahmine en yakın K sayısı kadar (özel olarak seçilmiş bir sayı) komşu bulur. Komşuların hangi sınıflara dahil olduğunu dikkate alarak bir karar verir ve bir cevap bulur.

Komşuları bulmak için Öklid Uzaklığı kullanılabilir.
"""

ort_knn = KNeighborsClassifier(n_neighbors = 10) #K komşu sayısı

ort_knn.fit(train_x,train_y) #Modelimizi eğitim verilerine göre eğittik.

"""KNN algoritmasında komşu sayısı modelimizin bilirlik oranı için önemlidir. Eğer komşu sayısı yeterli değilse modelimizin fazla güvenilir olmaz. Eğer komşu sayısı çok fazlaysa, model overfitting yaşar ve benzer şekilde, bu da modelin güvenilirliğini azaltır. Ayrıca overfitting zaman komplikasyonlarına yol açar, yani modelin tepki verme süresini uzatır. Daha iyi bir bilirlik oranı elde etmek için komşu sayısı değiştirilebilir."""

knn_test_values = ort_knn.predict(val_x) #Tahmin edilen KNN değerleri için değişkenlerden yararlanıyoruz.
#Bu değerleri test verilerimizin etiketleriyle, yani gerçek sonuçlarla, karşılaştıracağız
#ve başarı oranımızı göreceğiz.
true_predicts = 0
import numpy
valy = numpy.array(val_y)
for i in range(len(val_y)):
    if(valy[i] == knn_test_values[i]):
        true_predicts += 1


print("Test Variables Size : ",len(valy))
#Şimdi, başarı oranını yüzde cinsinden hesaplayalım.
#Toplam test verisi sayısı 30

knn_accuracy = 100*true_predicts/len(valy)
print("KNN Accuracy for ort dataset : %",knn_accuracy)

"""Şimdi elimizde hem lojistik regresyonun hem de KNN’nin bilirlik oranı var. Üçünü de yan yana görmek için bir tane daha grafik oluşturalım."""

plt.bar("Custom Model Acc",custom_model_accuracy)
plt.bar("Base Model Acc",base_model_accuracy)
plt.bar("KNN Acc",knn_accuracy)
plt.yticks([0,20,40,60,80,100]) #y ekseninde görmek istediğimiz rakamlar
plt.title("3 Models Comparison")

plt.show()

"""### Support Vector Machine (SVM)

SVM sınıfları (özellikleri) bir hiper düzlemle bölen makine öğrenmesi algoritmasıdır.
"""

ort_svm = svm.SVC(kernel = "poly").fit(train_x,train_y)

svm_predict = ort_svm.predict(val_x)

svm_accuracy = accuracy_score(valy,svm_predict)
svm_accuracy = svm_accuracy*100
print("SVM Accuracy for ort dataset : %",svm_accuracy)

plt.figure(figsize =(10,7))
plt.bar('Custom Model Acc',custom_model_accuracy)
plt.bar('Base Model Acc',base_model_accuracy)
plt.bar('KNN Acc',knn_accuracy)
plt.bar('SVM Acc',svm_accuracy)
plt.title("4 Model Comparison")


plt.show()

"""#Confusion Matrix"""

title1 = "Confusion matrix, without normalization"
title2 = "Normalized confusion matrix"

class_names = ["1", "2", "3", "4", "5"]

np.set_printoptions(precision=2)

fig, ax = plt.subplots(figsize=(10, 10))
#Confusion matrix, without normalization
disp = plot_confusion_matrix(ort_svm, val_x, val_y,
                                 display_labels=class_names,
                                 cmap=plt.cm.Blues,
                                 normalize=None,
                                 values_format = "d",
                                  ax=ax)
disp.ax_.set_title(title1)

plt.grid(False)
    
print(title1)
print(disp.confusion_matrix)


plt.show()

fig, ax2 = plt.subplots(figsize=(10, 10))
#Normalized confusion matrix
disp = plot_confusion_matrix(ort_svm, val_x, val_y,
                                 display_labels=class_names,
                                 cmap=plt.cm.Blues,
                                 normalize="true",
                                 values_format = ".2g",
                                  ax=ax2)
disp.ax_.set_title(title2)

plt.grid(False)
    
print(title2)
print(disp.confusion_matrix)


plt.show()

"""### Random Forest Classifier

Rastgele Orman daha başarılı ve daha stabilize bir model yaratmak amacıyla Karar Ağaçlarını birleştirerek rastgele bir orman yaratır.
"""

ort_randomforest = RandomForestClassifier(n_estimators = 500,
                                          max_features = "auto",
                                          max_depth = 8,
                                          min_samples_split = 5) 
#n _estimators parametresiyle ormanda bulunmasını istediğimiz karar ağacı sayısını belirliyoruz.

ort_randomforest.fit(train_x,train_y)

randomforest_accuracy = ort_randomforest.score(val_x,val_y)*100
print('Random Forest Accuracy for ort dataset on test data : %',randomforest_accuracy)
print('Random Forest Accuracy for ort dataset on train data : %',ort_randomforest.score(train_x,train_y)*100)

plt.figure(figsize =(14,7))
plt.bar('Custom Model Acc',custom_model_accuracy)
plt.bar('Base Model Acc',base_model_accuracy)
plt.bar('SVM Acc',svm_accuracy)
plt.bar('KNN Acc',knn_accuracy)
plt.bar('Random Forest Acc',randomforest_accuracy)
plt.yticks([i for i in range(10,105,5)])
plt.title("5 Model Comparison")

plt.show()

"""### SVM Modelinin Sonuçlarının İncelenmesi"""

val_predictions = ort_svm.predict(val_x)

print(val_predictions[:5], "\n")

print(val_y.head())

pred = val_predictions[-10:].astype("int64")
org = val_y[-10:].values
df_pred = pd.DataFrame({"preds" : pred, "labels":org})
df_pred

"""SVM modeli %81 accuracy oranına sahipti. Gerçek değerler ile tahmin edilen 10 değeri karşılaştırdığımızda da 10 not ortalamasından 8 tanesini doğru bildiği sonucuna varıyoruz."""



"""# Ortalamalar dahil edilmeyen dataset"""

data_file = "Data/Veriseti_Ortaokullar_GONDERILEN.xlsx"
data_original = pd.read_excel(data_file)
df = data_original.copy()
df = df.drop(columns=["okuladi", "okulno"])
df.head()

df.iloc[:, -3:] = df.iloc[:, -3:].astype("int64")

df.dtypes

def sifir_bir_duzelt(degisken):
  for i in df[degisken].index:
    if df[degisken][i] ==0:
      df[degisken][i] = 1
    elif df[degisken][i]==1:
      df[degisken][i]=0

sifir_bir_duzelt("Asag")
sifir_bir_duzelt("Bsag")
sifir_bir_duzelt("Aoz")
sifir_bir_duzelt("Boz")
sifir_bir_duzelt("ABayri")
sifir_bir_duzelt("Abirlikte")
sifir_bir_duzelt("Acalisma")
sifir_bir_duzelt("Bcalisma")
sifir_bir_duzelt("oda")
sifir_bir_duzelt("hastalik")
sifir_bir_duzelt("okul_dyk")
sifir_bir_duzelt("ozel_kurs")

df.head()

"""##Ortalama değişkenleri olmadan tahminleme"""

df_new = df.drop(["ort6", "ort5"], axis=1)



x_reduced_col_names = df_new.corr().abs()["ort7"].nlargest(10).index
df_new[x_reduced_col_names].corr()

x = df_new[x_reduced_col_names]
x.dtypes

x = x.drop("ort7", axis=1)
y = df_new.ort7

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

model = DecisionTreeRegressor(max_depth=4)

model.fit(train_x, train_y)

val_predictions = model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

"""### 5. sınıf not ortalaması olan dataset ile 6. sınıf notlarının tahmini"""

df_new = df.drop(["ort7"], axis=1)

x_reduced_col_names = df_new.corr().abs()["ort6"].nlargest(10).index
df_new[x_reduced_col_names].corr()

x = df_new[x_reduced_col_names]
x.dtypes

x = x.drop("ort6", axis=1)
y = df_new.ort6

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

model = DecisionTreeRegressor(max_depth=4)

model.fit(train_x, train_y)

val_predictions = model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

"""### 6. sınıf notları olmadan 7. sınıf notlarının tahmini"""



df_new = df.drop(["ort6"], axis=1)

x_reduced_col_names = df_new.corr().abs()["ort7"].nlargest(10).index
df_new[x_reduced_col_names].corr()

x = df_new[x_reduced_col_names]
x.dtypes

x = x.drop("ort7", axis=1)
y = df_new.ort7

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

model = DecisionTreeRegressor(max_depth=3)

model.fit(train_x, train_y)

val_predictions = model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)



"""### 5. sınıf notları olmadan 7. sınıf notlarının tahmini"""

df_new = df.drop(["ort5"], axis=1)

x_reduced_col_names = df_new.corr().abs()["ort7"].nlargest(10).index
df_new[x_reduced_col_names].corr()

x = df_new[x_reduced_col_names]
x.dtypes

x = x.drop("ort7", axis=1)
y = df_new.ort7

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

model = DecisionTreeRegressor(max_depth=4)

model.fit(train_x, train_y)

val_predictions = model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

"""# Sadece ortalama not verileri ile tahminleme"""

df_ort = df.iloc[:, -3:]
df_ort.head()

x = df_ort.drop("ort7", axis=1)
y = df_ort.ort7

train_x, val_x, train_y, val_y = train_test_split(x, y, random_state=42)

model = DecisionTreeRegressor(max_depth=5)

model.fit(train_x, train_y)

val_predictions = model.predict(val_x)

print("Eğitim doğruluğu: ", model.score(train_x, train_y)*100)
print("Test doğruluğu: ", model.score(val_x, val_y)*100)

