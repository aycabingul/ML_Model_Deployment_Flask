# -*- coding: utf-8 -*-
"""Lise_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vPfGXcbk18co5SUVv7oNnnBzlwWit0p4
"""



import tensorflow as tf
import pandas as pd
import os
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import  MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import plot_confusion_matrix
from keras import optimizers
from sklearn.metrics import confusion_matrix



os.chdir("/content/drive/MyDrive/Works/Bitirme")

data_file = "Data/Veriseti_Anadolu_Liseleri.xlsx"
data_original = pd.read_excel(data_file)
df = data_original.copy()
df = df.drop(columns=["okuladi", "okulno"])
df.head()

df.iloc[:, -7:] = df.iloc[:, -7:].astype("int64")

def sifir_bir_duzelt(degisken):
  for i in df[degisken].index:
    if df[degisken][i] ==0:
      df[degisken][i] = 1
    elif df[degisken][i]==1:
      df[degisken][i]=0

sifir_bir_duzelt("Asag")
sifir_bir_duzelt("Bsag")
sifir_bir_duzelt("Aoz")
sifir_bir_duzelt("Boz")
sifir_bir_duzelt("ABayri")
sifir_bir_duzelt("Abirlikte")
sifir_bir_duzelt("Acalisma")
sifir_bir_duzelt("Bcalisma")
sifir_bir_duzelt("oda")
sifir_bir_duzelt("hastalik")
sifir_bir_duzelt("okul_dyk")
sifir_bir_duzelt("ozel_kurs")
sifir_bir_duzelt("ortaokul_kurs")
sifir_bir_duzelt("ortaokul_ozelders")

df.head()



x_reduced_col_names = df.corr().abs()["ort11"].nlargest(10).index
df[x_reduced_col_names].corr()

x = df[x_reduced_col_names]
x.dtypes

x.shape

df_train = x.iloc[:800, :]
df_test = x.iloc[800:, :]

x_train = df_train[df_train.columns.difference(['ort11'])].values
y_train = df_train[['ort11']].values
x_test = df_test[df_test.columns.difference(['ort11'])].values

sc_x = StandardScaler()
sc_y = StandardScaler()

x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)
y_train = sc_y.fit_transform(y_train)

x_test



#train_x, test_x, train_y, test_y = train_test_split(x, y, random_state=42)

x_train

model = Sequential()
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(9, )))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(16, activation= 'relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(32, activation= 'relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(1, activation='linear'))
model.compile(optimizer="adam", loss='mean_squared_error', metrics=["mse"])
history = model.fit(x_train,y_train, validation_split=0.03, batch_size=16, epochs=75)

def plot_acc_loss(x):  
  
  loss = x.history["loss"]
  val_loss = x.history["val_loss"]
 
  
  print("loss =", loss[-1])
  print("val_loss =", val_loss[-1])
  epochs = range(1, len(loss) + 1)
  fig = plt.figure()
  

  plt.subplot(2,1,2)
  plt.plot(epochs, loss, "bo", label="Training loss")
  plt.plot(epochs, val_loss, "b", label="Validation loss")
  plt.title("Training and Validation Loss")
  plt.xlabel("Epochs")
  plt.ylabel("Loss")
  plt.legend()
  fig.tight_layout()
  plt.show()
  
  

plot_acc_loss(history)

y_pred = model.predict(x_test)
y_pred = sc_y.inverse_transform(y_pred)
y_pred = pd.DataFrame(y_pred)
y_pred = y_pred.rename(columns={0: "tahminler"})
y_pred = y_pred.astype("int64")
labels = df_test.ort11
df_preds = pd.DataFrame(y_pred[:10])


df_labels = pd.DataFrame(labels[:10])
df_labels = df_labels.rename(columns={0: "gerçek notlar"})
df_labels = df_labels.reset_index()
df_labels = df_labels.iloc[:, -1:]


df_tahminler = pd.concat([df_preds, df_labels.reindex(df_preds.index)], axis=1)
df_tahminler

"""#Classification"""



data_file = "Data/Veriseti_Anadolu_Liseleri.xlsx"
data_original = pd.read_excel(data_file)
df = data_original.copy()
df = df.drop(columns=["okuladi", "okulno"])
df.head()

from google.colab import drive
drive.mount('/content/drive')

def sifir_bir_duzelt(degisken):
  for i in df[degisken].index:
    if df[degisken][i] ==0:
      df[degisken][i] = 1
    elif df[degisken][i]==1:
      df[degisken][i]=0

sifir_bir_duzelt("Asag")
sifir_bir_duzelt("Bsag")
sifir_bir_duzelt("Aoz")
sifir_bir_duzelt("Boz")
sifir_bir_duzelt("ABayri")
sifir_bir_duzelt("Abirlikte")
sifir_bir_duzelt("Acalisma")
sifir_bir_duzelt("Bcalisma")
sifir_bir_duzelt("oda")
sifir_bir_duzelt("hastalik")
sifir_bir_duzelt("okul_dyk")
sifir_bir_duzelt("ozel_kurs")
sifir_bir_duzelt("ortaokul_kurs")
sifir_bir_duzelt("ortaokul_ozelders")

def puan_olcegi(ort):
  for i in df[ort].index:
    #if df[ort][i] >=0 and df[ort][i] <= 49,99:
     # df[ort][i] = 0
    if df[ort][i] >=0 and df[ort][i] <= 49.99:
      df[ort][i] = 0
    elif df[ort][i] >= 50 and df[ort][i] <=59.99:
      df[ort][i] = 1
    elif df[ort][i] >= 60 and df[ort][i] <=69.99:
      df[ort][i] = 2
    elif df[ort][i] >= 70 and df[ort][i] <=84.99:
      df[ort][i] = 3
    elif df[ort][i] >= 85 and df[ort][i] <=100:
      df[ort][i] = 4

puan_olcegi(ort = "ort9")
puan_olcegi(ort = "ort10")
puan_olcegi(ort = "ort11")
puan_olcegi(ort = "turkce9")
puan_olcegi(ort = "mat9")

df.iloc[:, -7:] = df.iloc[:, -7:].astype("int64")
df

df.iloc[714].ort11





df["ort11"][714] = 1

df.iloc[714].ort11

not49 = df.index[df['ort11'] == 49].tolist()
not49

x_reduced_col_names = df.corr().abs()["ort11"].nlargest(10).index
df[x_reduced_col_names].corr()

x = df[x_reduced_col_names]
x.dtypes

df_train = x.iloc[:800, :]
df_test = x.iloc[800:, :]

x_train = df_train[df_train.columns.difference(['ort11'])].values
y_train = df_train[['ort11']].values
x_test = df_test[df_test.columns.difference(['ort11'])].values
y_test = df_test[["ort11"]].values

np.unique(y_train)

sc_x = StandardScaler()
sc_y = StandardScaler()

x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)
#y_train = sc_y.fit_transform(y_train)

from keras.utils import to_categorical 
test_labels = to_categorical(y_train, dtype ="uint8", num_classes=5)



test_labels[1]

model = Sequential()
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(9, )))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(16, activation= 'relu'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(32, activation= 'relu'))



model.add(tf.keras.layers.Dense(5, activation='softmax'))

model.compile(optimizer=optimizers.Adamax(lr=5e-4), loss='categorical_crossentropy', metrics=["acc"])
history = model.fit(x_train,test_labels, validation_split=0.03, batch_size=8, epochs=50)

def plot_acc_loss(x):  
  acc = x.history["acc"]
  val_acc = x.history["val_acc"]
  loss = x.history["loss"]
  val_loss = x.history["val_loss"]
  print("acc =", acc[-1])
  print("val_acc = ", val_acc[-1])
  print("loss =", loss[-1])
  print("val_loss =", val_loss[-1])
  epochs = range(1, len(acc) + 1)
  fig = plt.figure()
  plt.subplot(2,1,1)
  plt.plot(epochs, acc, "bo", label="Training acc")
  plt.plot(epochs, val_acc, "b", label="Validation acc")
  plt.xlabel("Epochs")
  plt.ylabel("Accuracy")
  plt.title("Training and Validation Accuracy")

  plt.subplot(2,1,2)
  plt.plot(epochs, loss, "bo", label="Training loss")
  plt.plot(epochs, val_loss, "b", label="Validation loss")
  plt.title("Training and Validation Loss")
  plt.xlabel("Epochs")
  plt.ylabel("Loss")
  plt.legend()
  fig.tight_layout()
  plt.show()

plot_acc_loss(history)

pred_list = []
real_list = []

for i in np.arange(100):
  random=np.random.randint(1,100)
  data1 = x_test[random]


  y=model.predict(data1.reshape(1,9))
      
  predict_ind=np.argmax(y)
  
  pred_list.append(predict_ind)
  real_list.append(int(y_test[random]))

df_preds = pd.DataFrame(pred_list)
df_preds = df_preds.rename(columns={0: "tahminler"})
df_real = pd.DataFrame(real_list)
df_real = df_real.rename(columns={0: "gerçek notlar"})

df_tahminler = pd.concat([df_preds, df_real.reindex(df_preds.index)], axis=1)

def not_duzelt(degisken):
  for i in df_tahminler[degisken].index:
    if df_tahminler[degisken][i] ==0:
      df_tahminler[degisken][i] = 1
    elif df_tahminler[degisken][i]==1:
      df_tahminler[degisken][i]=2
    elif df_tahminler[degisken][i]==2:
      df_tahminler[degisken][i]=3
    elif df_tahminler[degisken][i]==3:
      df_tahminler[degisken][i]=4
    elif df_tahminler[degisken][i]==4:
      df_tahminler[degisken][i]=5

not_duzelt("tahminler")

not_duzelt("gerçek notlar")

df_tahminler

"""#Confusion Matrix"""

results = confusion_matrix(real_list, pred_list)
print(results)

fig, ax = plt.subplots()

ax.matshow(results, cmap = plt.cm.Blues)

for i in range(5):
  for j in range(5):
    c = results[j, i]
    ax.text(i, j, str(c), va="center", ha="center")

#plt.imshow(results, cmap='hot', interpolation='nearest', display_labels)
#plt.show()